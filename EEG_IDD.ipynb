{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0423dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob #'glob' is used to search for a file with a specific file name in a csv or text file format.\n",
    "import os #'os' is for interacting with the operating system.\n",
    "import mne #'mne' is an open-source Python module for processing, analysis, and visualization of functional neuroimaging data (EEG, MEG, sEEG,etc...).\n",
    "import numpy as np #numpy to deal with mathematical functions on arrays\n",
    "import pandas as pd #pandas to perform various functions on dataframes\n",
    "import matplotlib.pyplot\n",
    "import scipy # we us SciPy to help us interact with the data at a more complex level.\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7662d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are just importing our dataset.\n",
    "TDC_data_path=r'C:\\Users\\Aadithya\\OneDrive\\Desktop\\Data\\CleanData\\CleanData_TDC\\Rest'\n",
    "IDD_data_path=r'C:\\Users\\Aadithya\\OneDrive\\Desktop\\Data\\CleanData\\CleanData_IDD\\Rest'\n",
    "#IDD_data_path=os.path.abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca86b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this step we define a function to connvert our given matlab files to mne files so that we can easily use them in our model.\n",
    "def convertmat2mne(data):\n",
    "    ch_names = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4'] # Here we specify the channels and their type.\n",
    "    ch_types = ['eeg'] * 14\n",
    "    sampling_freq=128\n",
    "    info = mne.create_info(ch_names, ch_types=ch_types, sfreq=sampling_freq)\n",
    "    info.set_montage('standard_1020') # Here we specify the location of the elctrodes.\n",
    "    data=mne.io.RawArray(data, info)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=1,h_freq=30)\n",
    "    epochs=mne.make_fixed_length_epochs(data,duration=4,overlap=0)\n",
    "    return epochs.get_data() # As final output we now have data in a 3d format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8293097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Here we convert our data.\n",
    "idd_subject=[]\n",
    "for idd in glob(IDD_data_path + '/*.mat'):\n",
    "    data=scipy.io.loadmat(idd)['clean_data']\n",
    "    data=convertmat2mne(data)\n",
    "    idd_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2662d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Same as above.\n",
    "tdc_subject=[]\n",
    "for tdc in glob(TDC_data_path+'/*.mat'):\n",
    "    data=scipy.io.loadmat(tdc)['clean_data']\n",
    "    data=convertmat2mne(data)\n",
    "    tdc_subject.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c016d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n"
     ]
    }
   ],
   "source": [
    "# In this step we are finding out the length of each dataset to be evaluated.\n",
    "control_epochs_labels=[len(i)*[0] for i in tdc_subject]\n",
    "patients_epochs_labels=[len(i)*[1] for i in idd_subject]\n",
    "print(len(control_epochs_labels),len(patients_epochs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e265a829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 14 14\n"
     ]
    }
   ],
   "source": [
    "# Here we combine our two data sets to create one singular datatset.\n",
    "data_list=tdc_subject+idd_subject\n",
    "label_list=control_epochs_labels+patients_epochs_labels\n",
    "groups_list=[[i]*len(j) for i, j in enumerate(data_list)]\n",
    "print(len(data_list),len(label_list),len(groups_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab40e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf=GroupKFold()\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "class StandardScaler3D(BaseEstimator,TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape( -1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8df31c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 512, 14) (420,) (420,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_array=np.concatenate(data_list)\n",
    "label_array=np.concatenate(label_list)\n",
    "group_array=np.concatenate(groups_list)\n",
    "data_array=np.moveaxis(data_array,1,2)\n",
    "\n",
    "print(data_array.shape,label_array.shape,group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bf493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler3D()\n",
    "    train_features=scaler.fit_transform(train_features)\n",
    "    val_features=scaler.transform(val_features)\n",
    "   \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60b47f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 512, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c26ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Dense,concatenate,Flatten,GRU,Conv1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa71097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input):\n",
    "    conv1 = Conv1D(32, 2, strides=2,activation='relu',padding=\"same\")(input)\n",
    "    conv2 = Conv1D(32, 4, strides=2,activation='relu',padding=\"causal\")(input)\n",
    "    conv3 = Conv1D(32, 8, strides=2,activation='relu',padding=\"causal\")(input)\n",
    "    x = concatenate([conv1,conv2,conv3],axis=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae28ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input= Input(shape=(512,14))\n",
    "block1=block(input)\n",
    "block2=block(block1)\n",
    "block3=block(block2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ce156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_out1 = GRU(32,activation='relu',return_sequences=True)(block3)\n",
    "gru_out2 = GRU(32,activation='relu',return_sequences=True)(gru_out1)\n",
    "gru_out = concatenate([gru_out1,gru_out2],axis=2)\n",
    "gru_out3 = GRU(32,activation='relu',return_sequences=True)(gru_out)\n",
    "gru_out = concatenate([gru_out1,gru_out2,gru_out3])\n",
    "gru_out4 = GRU(32,activation='relu')(gru_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d2471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(1,activation='sigmoid')(gru_out4)\n",
    "model = Model(inputs=input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e401204b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 510ms/step - loss: 1.3079e-07 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9889\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 1s 446ms/step - loss: 1.3011e-07 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9889\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 431ms/step - loss: 1.2934e-07 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9889\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 439ms/step - loss: 1.2849e-07 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9889\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 1s 436ms/step - loss: 1.2760e-07 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9889\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 456ms/step - loss: 1.2689e-07 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9889\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 1s 459ms/step - loss: 1.2606e-07 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9889\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 1s 485ms/step - loss: 1.2566e-07 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9889\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 1s 481ms/step - loss: 1.2458e-07 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9889\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 1s 447ms/step - loss: 1.2419e-07 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 1s 451ms/step - loss: 1.2340e-07 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9889\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 1.2250e-07 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9889\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 1s 477ms/step - loss: 1.2199e-07 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9889\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 1.2124e-07 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9889\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 1s 433ms/step - loss: 1.2057e-07 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9889\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 1s 444ms/step - loss: 1.1996e-07 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9889\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 1s 442ms/step - loss: 1.1906e-07 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9889\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 1s 445ms/step - loss: 1.1839e-07 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9889\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 1s 464ms/step - loss: 1.1768e-07 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 457ms/step - loss: 1.1715e-07 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e17d94400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,train_labels,epochs=20,batch_size=128,validation_data=(val_features,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414f343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
